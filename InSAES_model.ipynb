{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:05.913487Z",
     "start_time": "2024-06-19T17:35:05.908252Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, Flatten, Dense"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:07.075885Z",
     "start_time": "2024-06-19T17:35:07.072516Z"
    }
   },
   "cell_type": "code",
   "source": "database = \"/Users/rumen/Plovdiv University/Дипломна работа/InSAES_data\"",
   "id": "2efeca21e2df6837",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:23.341123Z",
     "start_time": "2024-06-19T17:35:08.068056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extracting data\n",
    "features, total_emotions = [], []\n",
    "\n",
    "for x, _, z in os.walk(database):\n",
    "    for i in z:\n",
    "        if i.endswith(\".wav\"):\n",
    "            audio_path = os.path.join(x, i)\n",
    "            emotion = os.path.basename(x).split(\"_\")[-1]\n",
    "            audio, sr = librosa.load(audio_path, duration=3)\n",
    "            mfcc = np.mean(librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13), axis=1)\n",
    "            features.append(mfcc)\n",
    "            total_emotions.append(emotion)"
   ],
   "id": "9a8f528fac2531b0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:24.363972Z",
     "start_time": "2024-06-19T17:35:24.356134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features = np.array(features)\n",
    "total_emotions = np.array(total_emotions)"
   ],
   "id": "1bf23e3e319238ca",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:25.077781Z",
     "start_time": "2024-06-19T17:35:25.072423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert emotion names to numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(total_emotions)"
   ],
   "id": "3bf0a2114503d160",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lst = []\n",
    "\n",
    "for i in [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\"]:\n",
    "    curr_emotion_name = os.path.join(database, f\"YAF_{i}\")\n",
    "    if os.path.exists(curr_emotion_name):\n",
    "\n",
    "        random_data = np.random.choice([x for x in os.listdir(curr_emotion_name) if x.endswith(\".wav\")], size=3, replace=False)\n",
    "\n",
    "        for k in random_data[:1]:\n",
    "            file_path = os.path.join(curr_emotion_name, k)\n",
    "            audio, sr = librosa.load(file_path, duration=3)\n",
    "            lst.append((audio, sr, i))\n",
    "    else:\n",
    "        print(f\"Directory {curr_emotion_name} does not exist\")\n",
    "\n",
    "# Visualising results\n",
    "plt.figure(figsize=(12, 8))\n",
    "for (audio, sr, emotion), i in zip(lst, [\"b\", \"g\", \"r\", \"c\", \"m\", \"y\", \"k\"]):\n",
    "    plt.plot(audio, label=emotion, color=i)\n",
    "\n",
    "plt.title(\"Waveforms of Selected Samples\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "bf1b47592704e4bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def augment_audio(features_in, total_emotions_in):\n",
    "    lst_f = []\n",
    "    lst_e = []\n",
    "\n",
    "    for f, e in zip(features_in, total_emotions_in):\n",
    "        \n",
    "        lst_f.append(f)\n",
    "        lst_e.append(e)\n",
    "\n",
    "        \n",
    "        noise = np.random.randn(len(f))\n",
    "        lst_f.append(f + 0.005 * noise)\n",
    "        lst_e.append(e)\n",
    "\n",
    "        \n",
    "        lst_f.append(librosa.effects.time_stretch(f, rate=1.2))\n",
    "        lst_e.append(e)\n",
    "\n",
    "        \n",
    "        lst_f.append(librosa.effects.pitch_shift(f, sr=22050, n_steps=2))\n",
    "        lst_e.append(e)\n",
    "\n",
    "    return np.array(lst_f), np.array(lst_e)\n",
    "\n",
    "\n",
    "additional_features, augmented_t_emotions = augment_audio(features, total_emotions)\n",
    "\n",
    "# Visualising the original and additional samples\n",
    "print(\"Original samples:\", len(features))\n",
    "print(\"Current samples:\", len(additional_features))"
   ],
   "id": "d58a407387cfda5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T17:35:37.357431Z",
     "start_time": "2024-06-19T17:35:37.345996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "emotion_idxs = {\"angry\": 0, \"disgust\": 1, \"fear\": 2, \"happy\": 3, \"neutral\": 4, \"sad\": 5}\n",
    "encoded_labels = np.array([emotion_idxs.get(x, -1) for x in total_emotions])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[encoded_labels != -1],\n",
    "                                                    encoded_labels[encoded_labels != -1], test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape((*X_train.shape, 1))\n",
    "X_test = X_test.reshape((*X_test.shape, 1))\n",
    "\n",
    "# Convert the emotion labels to categorical format\n",
    "y_train = to_categorical(y_train, len(emotion_idxs))\n",
    "y_test = to_categorical(y_test, len(emotion_idxs))"
   ],
   "id": "a16a4e795ceff82e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Creating CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(13, 1, 1), padding=\"same\"))\n",
    "# Convert the output to one-dimensional form\n",
    "model.add(Flatten())\n",
    "# Adding dense layer\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "\n",
    "model.add(Dense(6, activation=\"softmax\"))\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ],
   "id": "b2c9ee4a1c70c86c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Model evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"***********\")\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test accuracy:\", accuracy)"
   ],
   "id": "11a6cf4986ba0834",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Accuracy of model on test data: \" , model.evaluate(X_test,y_test)[1]*100 , \"%\")",
   "id": "30f64a62df19aae2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"Model Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ],
   "id": "568c83a0788a77d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"val_accuracy\"])\n",
    "plt.title(\"Model Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "plt.show()"
   ],
   "id": "7d516984a4a0af4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predicted_emotions = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "true_emotions = np.argmax(y_test, axis=1)\n",
    "\n",
    "report = classification_report(true_emotions, predicted_emotions, \n",
    "                               target_names=[\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\"])\n",
    "print(report)"
   ],
   "id": "fac7ec5ad75c4263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history = model.fit(X_train, y_train, validation_split=0.3, epochs=10, batch_size=64)",
   "id": "fa494dde04910cf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(\"Accuracy of model on train data: \" , model.evaluate(X_train,y_train)[1]*100 , \"%\")",
   "id": "3bf095fb61133190",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.save(\"InSAES_model.h5\")\n",
    "print(\"Model saved correctly!\")"
   ],
   "id": "28d32f04bd4715cf",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
